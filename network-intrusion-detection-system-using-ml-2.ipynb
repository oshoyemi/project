{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem statement\nWe have a clean dataset that is generated from an IDS, also labeled denoting '0' for No-Attack and '1' for Attack.\nIn this dataset, we will go through different pre-processing well-known to drive this notebook to understandability.\nThe data is clean, yet we need to ensure that every feature matters to the model via 'Feature Importance' that comes out with the generated model.\n\nSource: http://www.secrepo.com/\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math, time, random, datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nimport missingno\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Read the training and test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ntrain = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv')\ntest = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_testing-set.csv')\ntest.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can do per below but we'd like to concatenate both the training set and the test set to avoid doing the preprocessing twice."},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train = train.drop(['label'], axis=1)\n#Y_train = train['label']\n#X_test = test.drop(['label'], axis=1)\n#Y_test = test['label']\n#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat([train,test]).reset_index(drop=True)\ncols_cat = data.select_dtypes('object').columns # To be explained later\ncols_numeric = data._get_numeric_data().columns # To be explained later","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Values:\n\n   <ul>\n        <li>\n        Check for missing values.\n        </li>\n         <li>\n        Replace those missing values.\n        </li>\n    </ul>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missingno.matrix(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is clean and there are no missing values. "},{"metadata":{},"cell_type":"markdown","source":"# Insights and steps: \n   <ul>\n        <li>\n        Data is clean.\n        </li>\n         <li>\n        Data still needs furthur processing in terms of One-hot-encoding for categorical data.\n                     E.g.: 'service' consists of different types, we have ftp, http, and '-' denoting (not available or None), So we will need to treat it as a missing value as we will change it from '-' to 'None' instead of dropping the whole column.\n        </li>\n            <li>\n        Removing unnecessary features like 'id'.\n        </li>\n    </ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['attack_cat'].unique()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data['proto'].unique() #This is definitely a categorical feature.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['service'].unique() #Here, we'll deal with the type of service that is '-'\ndata['service']= np.where(data['service'] == '-', 'None', data['service'])\nprint(data['service'].unique())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data['state'].unique() #Keep it.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Now, let's try to automate this process."},{"metadata":{"trusted":true},"cell_type":"code","source":"def Remove_dump_values(data, cols):\n    for col in cols:\n        data[col] = np.where(data[col] == '-', 'None', data[col])\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = data.columns\ndata_bin = Remove_dump_values(data, cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing unnecessary features:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bin = data_bin.drop(['id'], axis=1) #Remove Unnecessary features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['attack_cat'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_cat['attack_cat'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Categorical Features:\nOne Hot Encoding using cols_cat"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bin.drop(['attack_cat'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_cat = cols_cat.drop(['attack_cat'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" cols_cat.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Do one-hot encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bin_hot = pd.get_dummies(data_bin,columns=cols_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bin_hot.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Normalization:\nNormalize all the values in the dataset.\n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cols_numeric = list(cols_numeric)\ncols_numeric.remove('label')\ncols_numeric.remove('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bin_hot[cols_numeric] = data_bin_hot[cols_numeric].astype('float') ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data_bin_hot[cols_numeric] = (data_bin_hot[cols_numeric] - np.min(data_bin_hot[cols_numeric])) / np.std(data_bin_hot[cols_numeric])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bin_hot['attack_cat'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Test set splitting:\n"},{"metadata":{},"cell_type":"markdown","source":"We won't split the Data.. We do care about precision in our case!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn import metrics\nX = data_bin_hot.drop('label', axis=1)\nY = data_bin_hot['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"global X #To include in upcoming functions.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Models:\n<ul>\n    <li>\n        This is a Classification problem where we want to detect whether there is an attack or not.\n    </li>\n    <li>\n        We will use simple Logistic Regression.\n    </li>\n        <li>\n            K-Nearest Neighbour (Lazy Algorithm)\n    </li>\n        <li>\n        Decision Trees\n    </li>\n        <li>\n        Random Forest (gini)\n    </li>\n        <li>\n        Random Forest (Entropy or Information-gain)\n    </li>\n    </ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_algo(algo, x, y, cv):\n    #Fit the model\n    model = algo.fit(x, y)\n    \n    #Check its score\n    acc = round(model.score(x, y) *100, 2)\n    y_pred = model_selection.cross_val_predict(algo, x, y, cv=cv, n_jobs = -1)\n    \n    acc_cv = round(metrics.accuracy_score(Y,y_pred)*100, 2)\n    \n    return y_pred, acc, acc_cv, model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nstart_time = time.time()\npred_now, acc_lr, acc_cv_lr, lr = fit_algo(LogisticRegression(C=0.1)\n                                        , X, Y, 10)\n\nlr_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_lr)\nprint(\"Accuracy of CV: %s\" % acc_cv_lr)\nprint(\"Execution time: %s\" % lr_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def feature_plot(imp):\n    global X\n    fimp = pd.DataFrame({'Feature': X.columns, 'Importance' : np.round(imp)})\n    fimp =fimp.sort_values(by='Importance', ascending=False)\n    plt.figure(figsize=(10,10))\n    plt.plot(fimp['Feature'], fimp['Importance'])\n    plt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_plot(lr.coef_[0])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fimp_lr = pd.DataFrame({'Feature': X.columns, 'Importance' : np.round(lr.coef_[0])})\nfimp_lr =fimp_lr.sort_values(by='Importance', ascending=False)\nfimp_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.neighbors import KNeighborsClassifier\n#start_time = time.time()\n#pred_now, acc_knn, acc_cv_knn, knn = fit_algo(KNeighborsClassifier(n_neighbors = 3)\n #                                       , X, Y, 10)\n#knn_time = (time.time() - start_time)\n\n#print(\"Accuracy: %s\" % acc_knn)\n#print(\"Accuracy of CV: %s\" % acc_cv_knn)\n#print(\"Execution time: %s\" % knn_time)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[](http://)# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nstart_time = time.time()\npred_now, acc_dt, acc_cv_dt, dt = fit_algo(DecisionTreeClassifier(random_state = 1)\n                                        , X, Y, 10)\n\ndt_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_dt)\nprint(\"Accuracy of CV: %s\" % acc_cv_dt)\nprint(\"Execution time: %s\" % dt_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest (Gini)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nstart_time = time.time()\npred_now, acc_rf, acc_cv_rf, rf = fit_algo(RandomForestClassifier(n_estimators = 100)\n                                        , X, Y, 10)\n\nrf_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_rf)\nprint(\"Accuracy of CV: %s\" % acc_cv_rf)\nprint(\"Execution time: %s\" % rf_time)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest (Information Gain)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nstart_time = time.time()\npred_now, acc_rf2, acc_cv_rf2, rf2 = fit_algo(RandomForestClassifier(n_estimators = 100, criterion='entropy')\n                                        , X, Y, 10)\n\nrf2_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_rf2)\nprint(\"Accuracy of CV: %s\" % acc_cv_rf2)\nprint(\"Execution time: %s\" % rf2_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# Neural Networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nstart_time = time.time()\npred_now, acc_nn, acc_cv_nn, nn = fit_algo(MLPClassifier(hidden_layer_sizes = (20,), activation='relu', solver='adam')\n                                        , X, Y, 5)\n\nnn_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_nn)\nprint(\"Accuracy of CV: %s\" % acc_cv_nn)\nprint(\"Execution time: %s\" % nn_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gaussian Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nstart_time = time.time()\n\npred_now, acc_gnb, acc_cv_gnb, gnb= fit_algo(GaussianNB()\n                                        ,X,Y,5)\n\ngnb_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_gnb)\nprint(\"Accuracy of CV: %s\" % acc_cv_gnb)\nprint(\"Execution time: %s\" % gnb_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nstart_time = time.time()\n\npred_now, acc_gbt, acc_cv_gbt, gbt= fit_algo(GradientBoostingClassifier()\n                                        , X, Y, 10)\n\ngbt_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_gbt)\nprint(\"Accuracy of CV: %s\" % acc_cv_gbt)\nprint(\"Execution time: %s\" % gbt_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nstart_time = time.time()\n\npred_now, acc_svc, acc_cv_svc, svc= fit_algo(LinearSVC()\n                                        ,X,Y,10)\n\nsvc_time = (time.time() - start_time)\n\nprint(\"Accuracy: %s\" % acc_svc)\nprint(\"Accuracy of CV: %s\" % acc_cv_svc)\nprint(\"Execution time: %s\" % svc_time)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross-Validation Accuracy Comparison:"},{"metadata":{"trusted":true},"cell_type":"code","source":"algo_name = ['Log. Reg.', 'Decision Tree', 'RandomForest Gini', 'RandomForest IG', 'Neural Network', 'Gaussian NB', 'GBC', 'SVM']\nacc_df = pd.DataFrame({'Algorithm' : algo_name, 'Accuracy %' : [acc_cv_lr, acc_cv_dt, acc_cv_rf, acc_cv_rf2, acc_cv_nn, acc_cv_gnb, acc_cv_gbt, acc_cv_svc] })\nacc_df = acc_df.sort_values(by='Accuracy %', ascending = False)\nacc_df = acc_df.reset_index(drop=True)\nacc_df","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fimp_rf = pd.DataFrame({'Feature' : X.columns, 'Importance' : (rf.feature_importances_).astype(float)})\nfimp_rf = fimp_rf.sort_values(by='Importance', ascending=False)\nfimp_rf","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"feature_plot(rf.feature_importances_*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save the best accuracy model"},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'RandomForest_IG_IDS.sav'\npickle.dump(rf2, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the model (for future use)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the model from disk\nloaded_model = pickle.load(open(filename, 'rb'))\nresult = loaded_model.score(X, Y)\nprint(result)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}