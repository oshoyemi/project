{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import math, time, random, datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\nplt.style.use('seaborn')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nimport missingno\nimport pickle\nprint('matplotlib: {}'.format(matplotlib.__version__))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Read the training and test set.","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ntrain = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv')\ntest = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_testing-set.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([train,test])\nprint(data.shape)\ndata.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_cat = data.select_dtypes('object').columns # To be explained later\ncols_numeric = data._get_numeric_data().columns # To be explained later","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cols_cat)\nprint(cols_numeric)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in data:\n    print(data[column].value_counts())\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe().to_csv(\"describe_NB15.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Missing Values:\n\n   <ul>\n        <li>\n        Check for missing values.\n        </li>\n         <li>\n        Replace those missing values.\n        </li>\n    </ul>","metadata":{}},{"cell_type":"code","source":"print(data.isnull().sum())","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missingno.matrix(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data is clean and there are no missing values. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dropping the 'label' feature","metadata":{}},{"cell_type":"markdown","source":"**PCA** ","metadata":{}},{"cell_type":"markdown","source":"# Insights and steps: \n   <ul>\n        <li>\n        Data is clean.\n        </li>\n         <li>\n        Data still needs furthur processing in terms of One-hot-encoding for categorical data.\n                     E.g.: 'service' consists of different types, we have ftp, http, and '-' denoting (not available or None), So we will need to treat it as a missing value as we will change it from '-' to 'None' instead of dropping the whole column.\n        </li>\n            <li>\n        Removing unnecessary features like 'id'.\n        </li>\n    </ul>","metadata":{}},{"cell_type":"code","source":"data['proto'].unique() #This is definitely a categorical feature.","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['service'].unique() #Here, we'll deal with the type of service that is '-'\ndata['service']= np.where(data['service'] == '-', 'None', data['service'])\nprint(data['service'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['state'].unique() #Keep it.","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now, let's try to automate this process.","metadata":{}},{"cell_type":"code","source":"def Remove_dump_values(data, cols):\n    for col in cols:\n        data[col] = np.where(data[col] == '-', 'None', data[col])\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = data.columns\ndata_bin = Remove_dump_values(data, cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Removing unnecessary features:**","metadata":{}},{"cell_type":"code","source":"data_bin = data_bin.drop(['id'], axis=1) #Remove Unnecessary features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Categorical Features:\nOne Hot Encoding using cols_cat","metadata":{}},{"cell_type":"code","source":"data_bin.drop(['attack_cat'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_cat = cols_cat.drop(['attack_cat'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation = data_bin.corr()\n# print(type(correlation))\n# fig = plt.figure(figsize=(18,12))\n# ax = plt.subplot(1,1,1)\n# sns.heatmap(correlation.values,ax= ax, cmap='coolwarm')\n# # ax = sns.heatmap(data_bin, hue=data_bin.to_list)\n# # ax.legend(title='H')  # add a title to the legend\n# # plt.title('Correlation between different fearures')\n# # # sns.heatmap(data_bin.corr())","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Do one-hot encoding**","metadata":{}},{"cell_type":"code","source":"data_bin_hot = pd.get_dummies(data_bin,columns=cols_cat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_bin_hot.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data_bin_hot.drop('label', axis=1)\nY = data_bin_hot['label']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA().fit(X.values)\nplt.xlim([0, 10])\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.figure import Figure","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn import model_selection\nglobal X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_plot(imp):\n    global X\n    fimp = pd.DataFrame({'Feature': X.columns, 'Importance' : np.round(imp,5)})\n    fimp =fimp.sort_values(by='Importance', ascending=False)\n    plt.figure(figsize=(30,15))\n    plt.plot(fimp['Feature'], fimp['Importance'])\n    plt.xticks(rotation=90);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_algo(algo, x, y, cv):\n    #Fit the model\n    model = algo.fit(x, y)\n    \n    #Check its score\n    acc = round(model.score(x, y) *100, 2)\n    y_pred = model_selection.cross_val_predict(algo, x, y, cv=cv, n_jobs = -1)\n    \n    acc_cv = round(metrics.accuracy_score(Y,y_pred)*100, 2)\n    \n    return y_pred, acc, acc_cv, model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\npred_now, acc_rf, acc_cv_rf, rf = fit_algo(RandomForestClassifier(n_estimators = 100)\n                                        , X, Y, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_plot(rf.feature_importances_*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option(\"max_rows\",30)\nimp=rf.feature_importances_*100\nfimp = pd.DataFrame({'Feature': X.columns, 'Importance' : np.round(imp,5)})\nfimp =fimp.sort_values(by='Importance', ascending=False)\nfimp.index=np.arange(1,197)\nprint(fimp.head(30))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('col'+': '+'4')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}